# -*- coding: utf-8 -*-
"""final종합.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15k8VsCVrfPRzc2MTbJqdaBBMbp9YnivQ
"""

# !pip install sentence_transformers
# !pip install urllib3
# !pip install language-tool-python

import os
os.environ.setdefault("DJANGO_SETTINGS_MODULE", "core.settings")
import django
django.setup()
## BlogData를 import해옵니다
from apps.home.models import Result


import numpy as np
from numpy import dot
from numpy.linalg import norm
import pandas as pd
import urllib.request
from sentence_transformers import SentenceTransformer
import re
import time
from tqdm import tqdm
import os
import language_tool_python
from multiprocessing import Process
import csv


# input 데이터 2개
# df_right_answers = pd.read_csv('./EN_right_ans.csv',index_col=0)
# q_pd = pd.read_csv('./student_answer_Q1.csv',index_col=0)
# # df_right_answers1 = pd.read_csv('C:\Users\LG\Desktop\for_valid\django-datta-able-master 2\django-datta-able-master 2\student_answer_Q1.csv',index_col=0)

# def get_similarity(ans, right_ans, use="cosine"):
#     # Cosine Similarity
#     if use == "cosine":
#         return dot(ans, right_ans)/(norm(ans)*norm(right_ans))

# def sbert_final(df_right_answers, q_pd):
      
#   # for q in wai_questions:
#   #     q_pd = pd.read_csv(os.path.join(pathname,q),index_col=0)
#       model_ml = SentenceTransformer('sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens')
#       sbert_EN = SentenceTransformer('sentence-transformers/xlm-r-large-en-ko-nli-ststb')
#       # start = time.time()  # 시작 시간 저장
            
#       # answers = list(str(q_pd[q_pd.columns[0]]))
            

#       right_answers = df_right_answers['right_ans'][1]
#       right_answers_emb = sbert_EN.encode(right_answers)
      
#       # print(f"모범답안 embedding 시간 : {time.time() - start:.3f} 초")  # 현재시각 - 시작시간 = 실행 시간
#       # print()
#       # start = time.time()
#       similarity_cos = []
#       similarity_euclidean = []
#       similarity_pearson = []
#       similarity_total = []
#       answers=[]
#       for i in range(len(q_pd[q_pd.columns[0]])):
#         a=str(q_pd[q_pd.columns[0]][i])
#         answers.append(a)
      
#       for i in tqdm(range(len(answers))):
#           ans = answers[i]
#           ans_emb = sbert_EN.encode([ans])
#           r_emb = right_answers_emb
#           cos_sim = get_similarity(ans_emb[0], r_emb, use='cosine')
              
              
#           similarity_cos.append((right_answers, ans, cos_sim))
             
#       similarity_cos_sorted = sorted(similarity_cos, key = lambda x : x[2], reverse=True)           
#       df_similarity_cos = pd.DataFrame({'right_ans': [x[0] for x in similarity_cos],
#                                       'student_ans':[x[1] for x in similarity_cos],
#                                       'similarity':[x[2] for x in similarity_cos]})
          
           
#       tool = language_tool_python.LanguageTool('en-US')
      
#       # q_pd = q_pd.drop(columns = ['right_ans', 'similarity'])
#       df_similarity_cos['grammer_check'] = 0
#       for i in range(len(df_similarity_cos)):
#         text = df_similarity_cos.iloc[i][1]
#         print(text)

#         # get the matches
#         matches = tool.check(text)

#         print(matches)
#         print(len(matches))
#         df_similarity_cos['grammer_check'][i]=len(matches)

#       # 컬럼 명 변경하기(문제 번화 확인을 위해 키워드 컬럼명은 나중에 변경)
#       col_list = list(q_pd.columns)    # 컬럼명 리스트로 변경 후 내용 변경
#       col_list[0] = 'student_ans'
#       q_pd.columns = col_list
#       print(q_pd)

#       # 문항별 키워드 갯수 확인
#       keyword=q_pd.columns[1:]
#       n = len(keyword)
#       print(n)
            
#       # 문항번호와 키워드 분리
#       keyword_split = []
#       for s in range(0,n):
#         split_key= keyword[s].split('_')[1]
#         keyword_split.append(split_key)
#       print(keyword_split)

#       # 컬럼 명 변경하기
#       col_list = list(q_pd.columns)    
#       col_list[1:] = keyword_split          # 분리한 키워드 활용하여 컬럼명 변경/키워드와 동일하게 변경해야 label입력 가능
#       q_pd.columns = col_list
#       print(q_pd)
            
#       student_ans = q_pd[q_pd.columns[0]]
#       print(student_ans)  

#       label_encoder = []
#       label = 0        
#       for j in student_ans:
          
#           if 'parellel' in str(j):
#               label = 1
#           else:
#               label = 0
#             # print(label)
#           label_encoder.append(label)
#         # print(label_encoder)
#       q_pd['parallel'] = label_encoder
      

#       label_encoder1 = []
#       label1 = 0        
#       for j in student_ans:
          
#           if 'current flow' in str(j):
#               label = 1
#           else:
#               label = 0
#             # print(label)
#           label_encoder1.append(label1)
#         # print(label_encoder)
#       q_pd['current flow'] = label_encoder1
      

#       label_encoder2 = []
#       label2 = 0        
#       for j in student_ans:
          
#           if 'power amount' in str(j):
#               label = 1
#           else:
#               label = 0
#             # print(label)
#           label_encoder2.append(label2)
#         # print(label_encoder)
#       q_pd['power amount'] = label_encoder2
      

#       label_encoder3 = []
#       label3 = 0        
#       for j in student_ans:
          
#           if 'fuse' in str(j):
#               label = 1
#           else:
#               label = 0
#             # print(label)
#           label_encoder3.append(label3)
#         # print(label_encoder)
#       q_pd['fuse'] = label_encoder3
#       print(q_pd)

#       # 지금부터 최종 종합

#       q_pd_1=q_pd.drop(['student_ans'],axis=1)
        
#       df_similarity_cos['keyword_sum']=list(q_pd_1.sum(axis=1))  
#       df_similarity_cos_1=df_similarity_cos
#       df_similarity_cos_1=df_similarity_cos_1.drop(['right_ans','student_ans'],axis=1)
#       for i in range(len(df_similarity_cos)):
#         df_similarity_cos_1['similarity'][i]=df_similarity_cos_1['similarity'][i]*0.1
#         df_similarity_cos_1['keyword_sum'][i]=df_similarity_cos_1['keyword_sum'][i]*0.3
#       for i in range(len(df_similarity_cos)):
#         if df_similarity_cos_1['grammer_check'][i] > 3:
#             df_similarity_cos_1['grammer_check'][i] = 0
#         elif df_similarity_cos_1['grammer_check'][i] >= 1:
#             df_similarity_cos_1['grammer_check'][i] = 0.6
#         else :
#             df_similarity_cos_1['grammer_check'][i] = 1.2       
        
#       df_similarity_cos['score']=list(df_similarity_cos_1.sum(axis=1))

#       for i in range(len(df_similarity_cos)):
#         if df_similarity_cos['score'][i] < 0:
#             df_similarity_cos['score'][i] = 0

#       for i in range(len(df_similarity_cos)):
#         df_similarity_cos['score'][i] = round(df_similarity_cos['score'][i])      

#       df_similarity_cos.to_csv("./final_score_q1.csv")
      
# # input 데이터 두개를 변수로 함수 실행

# sbert_final(df_right_answers, q_pd)

# print("sbert_final"+"작업됨")

# final=pd.read_csv('./final_score_q1.csv',index_col=0)
# print(f"결과는 {final}입니다..")

# final1 = pd.DataFrame({"right_ans": [x[0] for x in final],"student_ans":[x[1] for x in final], "similarity":[x[2] for x in final],"grammer_check":[x[3] for x in final],"keyword_sum":[x[4] for x in final],"score":[x[5] for x in final]})
# 결과를 디비에 저장
# final.to_sql()
# -----------------------------------------------------------------------
df_right_answers = pd.read_csv('./EN_right_ans.csv',index_col=0)
q_pd = pd.read_csv('./student_key_q1.csv',index_col=0)

def get_similarity(ans, right_ans, use="cosine"):
    # Cosine Similarity
    if use == "cosine":
        return dot(ans, right_ans)/(norm(ans)*norm(right_ans))

def sbert_final(df_right_answers, q_pd):
      
  # for q in wai_questions:
  #     q_pd = pd.read_csv(os.path.join(pathname,q),index_col=0)
      model_ml = SentenceTransformer('sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens')
      sbert_EN = SentenceTransformer('sentence-transformers/xlm-r-large-en-ko-nli-ststb')
      # start = time.time()  # 시작 시간 저장
            
      # answers = list(str(q_pd[q_pd.columns[0]]))
            

      right_answers = df_right_answers['right_ans'][1]
      right_answers_emb = sbert_EN.encode(right_answers)
      
      # print(f"모범답안 embedding 시간 : {time.time() - start:.3f} 초")  # 현재시각 - 시작시간 = 실행 시간
      # print()
      # start = time.time()
      similarity_cos = []
      similarity_euclidean = []
      similarity_pearson = []
      similarity_total = []
      answers=[]
      for i in range(len(q_pd[q_pd.columns[0]])):
        a=str(q_pd[q_pd.columns[0]][i])
        answers.append(a)
      
      for i in tqdm(range(len(answers))):
          ans = answers[i]
          ans_emb = sbert_EN.encode([ans])
          r_emb = right_answers_emb
          cos_sim = get_similarity(ans_emb[0], r_emb, use='cosine')
              
              
          similarity_cos.append((right_answers, ans, cos_sim))
             
      similarity_cos_sorted = sorted(similarity_cos, key = lambda x : x[2], reverse=True)           
      df_similarity_cos = pd.DataFrame({'right_ans': [x[0] for x in similarity_cos],
                                      'student_ans':[x[1] for x in similarity_cos],
                                      'similarity':[x[2] for x in similarity_cos]})
          
           
      tool = language_tool_python.LanguageTool('en-US')
      
      # q_pd = q_pd.drop(columns = ['right_ans', 'similarity'])
      df_similarity_cos['grammer_check'] = 0
      for i in range(len(df_similarity_cos)):
        text = df_similarity_cos.iloc[i][1]
        print(text)

        # get the matches
        matches = tool.check(text)

        print(matches)
        print(len(matches))
        df_similarity_cos['grammer_check'][i]=len(matches)

      # 컬럼 명 변경하기(문제 번화 확인을 위해 키워드 컬럼명은 나중에 변경)
      col_list = list(q_pd.columns)    # 컬럼명 리스트로 변경 후 내용 변경
      col_list[0] = 'student_ans'
      q_pd.columns = col_list
      print(q_pd)

      # 문항별 키워드 갯수 확인
      keyword=q_pd.columns[1:]
      n = len(keyword)
      print(n)
      
      print('------------------')
      print(keyword)

      # 문항번호와 키워드 분리
      keyword_split = []
      for s in range(0,n):
        split_key= keyword[s]
        keyword_split.append(split_key)
      print(keyword_split)

      # 컬럼 명 변경하기
      col_list = list(q_pd.columns)    
      col_list[1:] = keyword_split          # 분리한 키워드 활용하여 컬럼명 변경/키워드와 동일하게 변경해야 label입력 가능
      q_pd.columns = col_list
      print(q_pd)
            
      student_ans = q_pd[q_pd.columns[0]]
      print(student_ans)  

      label_encoder = []
      label = 0        
      for j in student_ans:
          
          if q_pd.columns[1] in str(j):
              label = 1
          else:
              label = 0
            # print(label)
          label_encoder.append(label)
        # print(label_encoder)
      q_pd[q_pd.columns[1]] = label_encoder
      

      label_encoder1 = []
      label1 = 0        
      for j in student_ans:
          
          if q_pd.columns[2] in str(j):
              label = 1
          else:
              label = 0
            # print(label)
          label_encoder1.append(label1)
        # print(label_encoder)
      q_pd[q_pd.columns[2]] = label_encoder1
      

      label_encoder2 = []
      label2 = 0        
      for j in student_ans:
          
          if q_pd.columns[3] in str(j):
              label = 1
          else:
              label = 0
            # print(label)
          label_encoder2.append(label2)
        # print(label_encoder)
      q_pd[q_pd.columns[3]] = label_encoder2
      

      label_encoder3 = []
      label3 = 0        
      for j in student_ans:
          
          if q_pd.columns[4] in str(j):
              label = 1
          else:
              label = 0
            # print(label)
          label_encoder3.append(label3)
        # print(label_encoder)
      q_pd[q_pd.columns[4]] = label_encoder3
      print(q_pd)

      # 지금부터 최종 종합

      q_pd_1=q_pd.drop(['student_ans'],axis=1)
        
      df_similarity_cos['keyword_sum']=list(q_pd_1.sum(axis=1))  
      df_similarity_cos_1=df_similarity_cos
      df_similarity_cos_1=df_similarity_cos_1.drop(['right_ans','student_ans'],axis=1)
      for i in range(len(df_similarity_cos)):
        df_similarity_cos_1['similarity'][i]=df_similarity_cos_1['similarity'][i]*0.1
        df_similarity_cos_1['keyword_sum'][i]=df_similarity_cos_1['keyword_sum'][i]*0.3
      for i in range(len(df_similarity_cos)):
        if df_similarity_cos_1['grammer_check'][i] > 3:
            df_similarity_cos_1['grammer_check'][i] = 0
        elif df_similarity_cos_1['grammer_check'][i] >= 1:
            df_similarity_cos_1['grammer_check'][i] = 0.6
        else :
            df_similarity_cos_1['grammer_check'][i] = 1.2       
        
      df_similarity_cos['score']=list(df_similarity_cos_1.sum(axis=1))

      for i in range(len(df_similarity_cos)):
        if df_similarity_cos['score'][i] < 0:
            df_similarity_cos['score'][i] = 0

      for i in range(len(df_similarity_cos)):
        df_similarity_cos['score'][i] = round(df_similarity_cos['score'][i])      

      df_similarity_cos.to_csv(f"./final_score_q1.csv")

# input 데이터 두개를 변수로 함수 실행
sbert_final(df_right_answers, q_pd)

print("sbert_final"+"작업됨")
# final=pd.read_csv('/content/final_score_q1.csv',index_col=0)
# final


